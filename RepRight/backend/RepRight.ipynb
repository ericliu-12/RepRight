{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0MH3oqgYsUA8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize mediapipe pose estimation model\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "# pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get keypoints from image with mediapipe\n",
        "def extract_keypoints(image):\n",
        "    # convert image to RGB\n",
        "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = pose.process(rgb_image)\n",
        "\n",
        "    # if no landmarks (joints) return zeros\n",
        "    if not results.pose_landmarks:\n",
        "        return np.zeros(33*3)\n",
        "    \n",
        "    # get keypoints in (x,y,z) coordinates format\n",
        "    keypoints = []\n",
        "    for landmark in results.pose_landmarks.landmark:\n",
        "        keypoints.append([landmark.x, landmark.y, landmark.z])\n",
        "    return np.array(keypoints).flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load images and their labels\n",
        "def load_images(folder):\n",
        "    data = []\n",
        "    labels = []\n",
        "    #big3 = [\"bench press\",\"squat\", \"deadlift\" ]\n",
        "    big3 = [\"push up\",\"barbell biceps curl\", \"squat\" ]\n",
        "    # go through each folder\n",
        "    for exercise in os.listdir(folder):\n",
        "        if exercise in big3:\n",
        "            exercise_folder = os.path.join(folder,exercise)\n",
        "            if os.path.isdir(exercise_folder):\n",
        "                # go through each image in folder\n",
        "                for img_file in os.listdir(exercise_folder):\n",
        "                    img_path = os.path.join(exercise_folder, img_file)\n",
        "\n",
        "                    # read image\n",
        "                    image = cv2.imread(img_path)\n",
        "                    if image is not None:\n",
        "                        keypoints = extract_keypoints(image)\n",
        "                        data.append(keypoints)\n",
        "                        labels.append(exercise)\n",
        "    return np.array(data), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load images from workout data folder\n",
        "\"\"\" base_folder = \"./workout_data/images\"\n",
        "data,labels = load_images(base_folder) \"\"\"\n",
        "labels = ['barbell biceps curl', 'push up', 'squat']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# encode exercise names into numerical format\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "trainData, testData, trainLabel, testLabel = train_test_split(data, labels_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# build neural network to classify exercises based on keypoints\n",
        "model = models.Sequential([\n",
        "    layers.Dense(128, activation=\"relu\", input_shape=(trainData.shape[1],)),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(len(np.unique(labels_encoded)), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# def create_exercise_recognition_model(num_exercises, sequence_length=30):\n",
        "#     input_layer = tf.keras.Input(shape=(sequence_length, 33, 3))  # Sequence of 33 pose landmarks, 3 coordinates each\n",
        "    \n",
        "#     x = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(input_layer)\n",
        "#     x = tf.keras.layers.LSTM(128, return_sequences=True)(x)\n",
        "#     x = tf.keras.layers.LSTM(64)(x)\n",
        "#     x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "#     output = tf.keras.layers.Dense(num_exercises, activation='softmax')(x)\n",
        "\n",
        "#     model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
        "#     return model\n",
        "\n",
        "# # Create and compile the model\n",
        "# num_exercises = 5  # Adjust based on the number of exercises you want to recognize\n",
        "# sequence_length = 30  # Adjust based on your video length and frame rate\n",
        "# model = create_exercise_recognition_model(num_exercises, sequence_length)\n",
        "\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(trainData, trainLabel, epochs=10, validation_data=(testData, testLabel))\n",
        "# model.fit(trainData, trainLabel, epochs=5, validation_data=(testData, testLabel), batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(testData, testLabel)\n",
        "print(f\"test accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dongk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "new_model = tf.keras.models.load_model('RepModel.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use trained model to predict on new images\n",
        "def classify_image(image_path, model):\n",
        "    image = cv2.imread(image_path)\n",
        "    keypoints = extract_keypoints(image)\n",
        "    keypoints = np.expand_dims(keypoints, axis=0)\n",
        "    prediction = model.predict(keypoints)\n",
        "    predicted_class = label_encoder.inverse_transform([np.argmax(prediction)])\n",
        "    return predicted_class[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_video(video_path, model):\n",
        "    vid = cv2.VideoCapture(video_path)\n",
        "    if not vid.isOpened():\n",
        "        print(\"Error opening video file\")\n",
        "        return\n",
        "    dict1 = {}\n",
        "    while vid.isOpened():\n",
        "        ret, frame = vid.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        keypoints = extract_keypoints(frame)\n",
        "        keypoints = np.expand_dims(keypoints, axis=0)\n",
        "        prediction = model.predict(keypoints)\n",
        "        predicted_class = label_encoder.inverse_transform([np.argmax(prediction)])\n",
        "        if predicted_class[0] not in dict1:\n",
        "            dict1[predicted_class[0]] =1\n",
        "        else:\n",
        "            dict1[predicted_class[0]] +=1\n",
        "        lol = max(dict1, key=dict1.get)\n",
        "\n",
        "        print(predicted_class)\n",
        "        # cv2.putText(frame, f'Predicted: {predicted_class[0]}', (10, 30), \n",
        "        #     cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "        cv2.putText(frame, f'Predicted: {lol}', (10, 30), \n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "        cv2.imshow(\"Video classification\", frame)\n",
        "\n",
        "        # break loop on 'q' key press\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    vid.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    # return predicted_class[0]\n",
        "    maxv = None  # Initialize maxv to negative infinity\n",
        "    curv = None  \n",
        "    for v in dict1:\n",
        "        if  maxv == None or dict1[v] > dict1[maxv]:\n",
        "            cur1 = dict1[v]\n",
        "            curv = v\n",
        "            max1 = cur1\n",
        "            maxv = curv\n",
        "    return maxv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "['barbell biceps curl']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dongk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
            "c:\\Users\\dongk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "['barbell biceps curl']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "['barbell biceps curl']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "['barbell biceps curl']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dongk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
            "c:\\Users\\dongk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
            "c:\\Users\\dongk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "['barbell biceps curl']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "['barbell biceps curl']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "['barbell biceps curl']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dongk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
            "c:\\Users\\dongk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
            "c:\\Users\\dongk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "['barbell biceps curl']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "['barbell biceps curl']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "['barbell biceps curl']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dongk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
            "c:\\Users\\dongk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
          ]
        }
      ],
      "source": [
        "# Repetition counter\n",
        "from rep_counting.pkg.kps_metrics import KpsMetrics\n",
        "from rep_counting.rep_counter import RepetitionCounter\n",
        "\n",
        "DEFAULT_CONFIG_DIR = \"./rep_counting/smart_trainer_config/config.json\"\n",
        "\n",
        "exercise_dict = {'barbell biceps curl': 'bicep_curls', 'push up': 'push_ups', 'squat': 'squats'}\n",
        "\n",
        "vid = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
        "if not vid.isOpened():\n",
        "    print(\"Error opening video file\")\n",
        "dict1 = {}\n",
        "maxv = None  # Initialize maxv to negative infinity\n",
        "curv = None\n",
        "\n",
        "rep_counter = RepetitionCounter(config_path=DEFAULT_CONFIG_DIR)\n",
        "# rep_counter.set_metric(\"bicep_curls\")\n",
        "\n",
        "while vid.isOpened():\n",
        "    ret, frame = vid.read()\n",
        "    if not ret:\n",
        "        break\n",
        "        \n",
        "    while sum(dict1.values()) < 10:\n",
        "        for v in dict1:\n",
        "            if maxv == None or dict1[v] > dict1[maxv]:\n",
        "                cur1 = dict1[v]\n",
        "                curv = v\n",
        "                max1 = cur1\n",
        "                maxv = curv\n",
        "        \n",
        "        keypoints = extract_keypoints(frame)\n",
        "        keypoints = np.expand_dims(keypoints, axis=0)\n",
        "        prediction = new_model.predict(keypoints)\n",
        "        predicted_class = label_encoder.inverse_transform([np.argmax(prediction)])\n",
        "        if predicted_class[0] not in dict1:\n",
        "            dict1[predicted_class[0]] =1\n",
        "        else:\n",
        "            dict1[predicted_class[0]] +=1\n",
        "        lol = max(dict1, key=dict1.get)\n",
        "        \n",
        "        cv2.putText(frame, f'Predicted: {maxv}', (10, 30), \n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "        cv2.imshow(\"Video classification\", frame)\n",
        "\n",
        "        print(predicted_class)\n",
        "    \n",
        "    # cv2.putText(frame, f'Predicted: {predicted_class[0]}', (10, 30), \n",
        "    #     cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "    cv2.putText(frame, f'Predicted: {maxv}', (10, 30), \n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "    # print(predicted_class)\n",
        "    # cv2.putText(frame, f'Predicted: {predicted_class[0]}', (10, 30), \n",
        "    #     cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "    \n",
        "    rep_counter.set_metric(exercise_dict[maxv])\n",
        "    \n",
        "    kps_norm = rep_counter.update_metric(frame)\n",
        "    frame = rep_counter.draw_kps_skeleton(frame, kps_norm, 5)\n",
        "    metric = rep_counter.get_metric(rep_counter.current_metric_name)\n",
        "    \n",
        "    cv2.putText(frame, f'Reps: {str(metric.reptition_count)}', (10, frame.shape[0] - 10), \n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "    cv2.putText(frame, f'Predicted: {maxv}', (10, 30), \n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "    cv2.imshow(\"Video classification\", frame)\n",
        "    \n",
        "    # break loop on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "vid.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress specific UserWarning from protobuf\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=r'SymbolDatabase.GetPrototype\\(\\) is deprecated')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_test_img = \"./test_data/jessefront_curl.mov\"\n",
        "# predicted_exercise = classify_image(path_test_img)\n",
        "predicted_exercise = classify_video(path_test_img, new_model)\n",
        "print(f\"predicted exercise: {predicted_exercise}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_format = 'keras'\n",
        "model.save('RepModel.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('RepModel.keras')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open('RepModelLite.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
